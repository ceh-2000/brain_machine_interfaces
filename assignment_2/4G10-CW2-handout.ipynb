{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4G10 Coursework 2: predicting hand kinematics from neural data\n",
    "\n",
    "\n",
    "Please read carefully the last section of this notebook, which gives some of our expectations regarding your report.\n",
    "\n",
    "In this handout, \n",
    "- <u>text that is underlined</u> corresponds to things you have to do / implement.\n",
    "- **text in bold** corresponds to questions you need to answer in some form in your report.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:34.996076Z",
     "start_time": "2024-12-18T15:00:34.422838Z"
    }
   },
   "source": [
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "random.seed(1)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup\n",
    "\n",
    "In this piece of 4G10 coursework, you will use neural data recorded in the primary motor cortex (M1) of a reaching monkey to predict the kinematics of the monkey's hand.\n",
    "\n",
    "The monkey initiated each trial by placing their hand in the center of a fronto-parallel screen. A target then appeared on the screen. The monkey had to wait for a ‘go’ cue before making a reaching movement towards the instructed target. The targets were placed in various positions in a virtual maze, which changed in each trial, forcing the monkey to make a variety of reaching movements across trials.\n",
    "\n",
    "The activity of $N=162$ motor cortical neurons was recorded simultaneously, alongside the kinematics of the animal's hand.\n",
    "\n",
    "In the dataset presented below, all time series are partitioned into trials. Each trial begins at the go cue and lasts 800ms ($T = 16$ bins of 50ms duration) — roughly the duration of a reach. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:35.739289Z",
     "start_time": "2024-12-18T15:00:35.000752Z"
    }
   },
   "source": [
    "# grab the data from the server\n",
    "r = requests.get('http://4G10.cbl-cambridge.org/data.npz', stream = True)\n",
    "data = np.load(BytesIO(r.raw.read()))"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among other things (detailed later), this dictionary numerical arrays indexed by the following keys:\n",
    "- `\"hand_train\" (2 × 400 × T)`: 2D velocity (X/Y) of the monkey's hand in 400 ‘train’ trials;\n",
    "- `\"neural_train\" (N × 400 × T)`: neural activity (spike counts) in the same 400 ‘train’ trials;\n",
    "- `\"neural_test\" (N × 100 × T)`: neural activity (spike counts) in 100 ‘test’ trials.\n",
    "\n",
    "E.g.:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:35.787086Z",
     "start_time": "2024-12-18T15:00:35.784028Z"
    }
   },
   "source": [
    "hand_train = data[\"hand_train\"]\n",
    "hand_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 400, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this CW is to implement some of the modelling / decoding techniques you have been taught in lectures, to predict the monkey's 2D hand velocity in the 100 test trials for which you are only given neural activity. Your predictions will be based on the training data provided (`hand_train, neural_train`)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Baseline decoder: simple Gaussian smoothing + linear regression\n",
    "\n",
    "To establish a meaningful baseline, you will first implement a very simple two-stage decoder.\n",
    "In the first stage, you will smooth the spike count time series of each neuron by convolving it with a Gaussian filter of width $\\sigma$; in continuous time, such a Gaussian filter is given by $f(t) \\propto \\exp(-t^2/2\\sigma^2)$."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:35.798513Z",
     "start_time": "2024-12-18T15:00:35.795643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gaussian_smooth_idx(sigma, data, smoothed_data, shape, idx):\n",
    "    # Basically, for some t away from a cell, we decide how much to weight that in our observation. So if t=0 (on that observation), weight is maximized at 1 (decays as we move away).\n",
    "    time_indices = np.arange(shape[2]) # Shape is neurons x trials x time steps\n",
    "    mask = np.abs(time_indices - idx)\n",
    "    mask = np.expand_dims(mask, axis=(0, 1)) # Cast over neuron and trial dimensions\n",
    "    mask = np.broadcast_to(mask, shape)\n",
    "    mask = np.exp(-(mask**2)/(sigma**2))\n",
    "    \n",
    "    # Normalize the mask to ensure it sums to 1 across time dimension\n",
    "    normalization_factor = np.sum(mask, axis=2, keepdims=True)  # Sum over time steps\n",
    "    mask = mask / normalization_factor  # Normalize the mask\n",
    "    \n",
    "    # Multiply each value of mask by original value and then average\n",
    "    weighted_data = mask * data\n",
    "    smoothed_data[:, :, idx] = np.sum(weighted_data, axis = 2) # Sum across weighted time steps\n",
    "\n",
    "# Test the function\n",
    "test_array = np.array(\n",
    "    [[[3, 7],\n",
    "  [5, 1],\n",
    "  [0, 9]],\n",
    " [[0, 4],\n",
    "  [7, 3],\n",
    "  [2, 7],],\n",
    " [[2, 0],\n",
    "  [0, 4],\n",
    "  [5, 5]]])\n",
    "test_smoothed_array = np.zeros(test_array.shape)\n",
    "gaussian_smooth_idx(10, test_array, test_smoothed_array, test_array.shape, 1)\n",
    "# print(test_array, test_smoothed_array)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:35.804374Z",
     "start_time": "2024-12-18T15:00:35.802933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gaussian_smooth(sigma, data):\n",
    "    shape = data.shape\n",
    "    smoothed_data = np.zeros(shape)\n",
    "    for idx in range(shape[2]): # Iterate over the time bins\n",
    "        gaussian_smooth_idx(sigma, data, smoothed_data, shape, idx)\n",
    "    return smoothed_data"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:35.919523Z",
     "start_time": "2024-12-18T15:00:35.810240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Stage 1: Smoothing spike count using gaussian filter of width sigma\n",
    "# Kernels say how we take an average with neighboring points. Here, we are using the Gaussian curve to indicate importance of nearby points\n",
    "\n",
    "# If time bins are width 50 ms, then 0.4 corresponds to 20 ms and 1.6 corresponds to 80 ms\n",
    "sigma = 1.6 # +/- milliseconds (ms)\n",
    "neural_train = data[\"neural_train\"]\n",
    "print(neural_train.shape)\n",
    "\n",
    "# Container to hold results of smoothing train set\n",
    "smoothed_neural_train = gaussian_smooth(sigma, neural_train)\n",
    "\n",
    "# As sigma grows, we move to an unweighted average (more smooth)\n",
    "# As sigma shrinks we care only about time steps very close (less smooth)\n",
    "print(smoothed_neural_train.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 400, 16)\n",
      "(162, 400, 16)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:36.157106Z",
     "start_time": "2024-12-18T15:00:35.929846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's plot the smoothing for the report\n",
    "neuron = 2\n",
    "trial = 0\n",
    "time_axis = np.arange(0, 751, 50) # Time bins\n",
    "slice_to_plot = neural_train[neuron, trial, :] # First neuron, first trial, all time bins\n",
    "smooth_slice_to_plot = smoothed_neural_train[neuron, trial, :] # First neuron, first trial, all time bins\n",
    "\n",
    "# Combine data with the new dimension\n",
    "slice_to_plot_2d = np.vstack([time_axis, slice_to_plot])\n",
    "smooth_slice_to_plot_2d = np.vstack([time_axis, smooth_slice_to_plot])\n",
    "\n",
    "# Create a single plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Original data histogram\n",
    "plt.bar(time_axis, slice_to_plot, width=50, align='edge', color='blue', alpha=1.0, label=\"Original Data\")\n",
    "\n",
    "# Smoothed data histogram (plotted on top)\n",
    "plt.bar(time_axis, smooth_slice_to_plot, width=50, align='edge', color='green', alpha=1.0, label=\"Smoothed Data\")\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(f\"Original and Smoothed Data Histograms ($\\\\sigma = {sigma}$)\", fontsize=16)\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Spike count (frequency)\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot as a high DPI image\n",
    "plt.savefig(f'plots/original_and_smoothed_data_histograms_sigma={sigma}.pdf', dpi=300)  # Save as PNG with 300 DPI for high resolution\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "heading_collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "In the second stage, you will use ridge regression to learn an instantaneous linear decoder given by\n",
    "\n",
    "$$ \\hat{v}_{k,t} = W \\tilde{x}_{k,t} $$\n",
    "\n",
    "where $\\hat{v}_{k, t} \\in \\mathbb{R}^2$ is the predicted velocity of the hand in test trial $k$ and time bin $t$, $\\tilde{x}_{k, t} \\in \\mathbb{R}^N$ is the $t^\\text{th}$ time bin of the temporally smoothed spike counts in test trial $k$, and $W$ is a `2 × N` matrix of decoding weights. Note that the hand velocity data has been centered already, so there is no need to include a bias term in the regression.\n",
    "\n",
    "The optimal ridge regression weights are given by\n",
    "$$  W^\\star = V \\tilde{X}^\\top (\\tilde{X} \\tilde{X}^\\top + \\lambda I_N )^{-1} $$\n",
    "where $V$ is the $2 × (400*16)$ matrix of hand velocities from the training set (with all trials and time bins concatenated horizontally), and similarly $\\tilde{X}$ is the $N × (400*16)$ matrix of smoothed neural spike counts in the training set.\n",
    "\n",
    "In the equation above, $\\lambda$ is a regularisation parameter which helps protect against overfitting.\n",
    "The choice of value for this parameter is left up to you, so long as you can provide a justification (there are several sensible possibilities).\n",
    "\n",
    "The goal here is to make the best possible predictions you can of the held out hand velocity data in test trials, based on the neural activity in the same trials. When you are ready to test your predictions, you can submit them as a 3D numpy array of shape `2 × 100 × 16` to http://4G10.cbl-cambridge.org (note: http, not https). If you get a “HTTP error 400” back, it probably means the format is wrong. Your numpy array must be saved using the `np.save(\"filename.npy\", my_array)` function; the server also expects the array to be of `float64` numerical type — this should be the default in numpy, but if in doubt you can always cast using `my_array.as_type(\"float64\")`. When you submit, please indicate your candidate number and choose \"Simple Gaussian smoothing\" in the dropdown list. Upon uploading, you will receive immediate feedback in the form of an $R^2$ coefficient. The closer to 1, the better!"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:36.170302Z",
     "start_time": "2024-12-18T15:00:36.168432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_W_star(X, V, l):\n",
    "    # Why ridge regression? reduce covariance of parameters by increasing diagonal (lambda * I_N) so ratio of variance to covariance is increased\n",
    "    \n",
    "    I_N = np.eye(X.shape[0])\n",
    "    \n",
    "    V_X_T = np.tensordot(V, X.T, axes=([2, 1], [0, 1]))\n",
    "    \n",
    "    X_X_T = np.tensordot(X, X.T, axes=([2, 1], [0, 1]))\n",
    "    \n",
    "    inv_mat = np.linalg.inv(X_X_T + l * I_N)\n",
    "    \n",
    "    W_star = np.tensordot(V_X_T, inv_mat, axes=([1], [0]))\n",
    "    \n",
    "    return W_star"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:36.176902Z",
     "start_time": "2024-12-18T15:00:36.175628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = smoothed_neural_train\n",
    "V = hand_train\n",
    "l = 100"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:36.189342Z",
     "start_time": "2024-12-18T15:00:36.182373Z"
    }
   },
   "cell_type": "code",
   "source": "W_star = compute_W_star(X, V, l)",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:36.223565Z",
     "start_time": "2024-12-18T15:00:36.195233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "neural_test = data[\"neural_test\"]\n",
    "test_shape = neural_test.shape\n",
    "\n",
    "# Container to hold results of smoothing on test set\n",
    "smoothed_neural_test = gaussian_smooth(sigma, neural_test)\n",
    "\n",
    "V_test = np.tensordot(W_star, smoothed_neural_test, axes=([1],[0]))\n",
    "print(V_test.shape)\n",
    "\n",
    "np.save(\"outputs/V_test_baseline.npy\", V_test)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100, 16)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:36.288874Z",
     "start_time": "2024-12-18T15:00:36.287446Z"
    }
   },
   "cell_type": "code",
   "source": "# Your test R2 is: 0.445",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:36.301648Z",
     "start_time": "2024-12-18T15:00:36.300266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reset seeds after messing around with plotting\n",
    "# np.random.seed(0)\n",
    "# random.seed(1)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:45.005898Z",
     "start_time": "2024-12-18T15:00:36.309101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use k-fold cross validation to choose lambda\n",
    "num_folds = 5\n",
    "fold_size = X.shape[1] / num_folds\n",
    "sigmas = [0.4, 1, 1.6]\n",
    "ls = [0.1, 1, 10, 100, 1000]\n",
    "\n",
    "df = pd.DataFrame(columns=[\"sigma\", \"lambda\", \"value\"])\n",
    "\n",
    "# Clean data copy \n",
    "neural_train = data[\"neural_train\"]\n",
    "\n",
    "for sigma in sigmas:\n",
    "    for l in ls:\n",
    "        fold_r2s = []\n",
    "        for i in range(num_folds):\n",
    "            start_idx = int(fold_size * i)\n",
    "            \n",
    "            # Figure out current validation indices\n",
    "            val_indices = np.arange(start_idx, start_idx + fold_size).astype(int)\n",
    "            \n",
    "            # Training indices are everything else\n",
    "            train_indices = np.setdiff1d(np.arange(X.shape[1]), val_indices).astype(int)\n",
    "            \n",
    "            # Extract test set (everything else)\n",
    "            X_train = neural_train[:, train_indices, :]\n",
    "            X_train_smooth = gaussian_smooth(sigma, X_train)\n",
    "            X_val = neural_train[:, val_indices, :]\n",
    "            X_val_smooth = gaussian_smooth(sigma, X_val)\n",
    "            \n",
    "            V_train = V[:, train_indices, :]\n",
    "            V_val = V[:, val_indices, :]\n",
    "            \n",
    "            W_star = compute_W_star(X_train_smooth, V_train, l)\n",
    "            V_pred = np.tensordot(W_star, X_val_smooth, axes=([1], [0]))\n",
    "            \n",
    "            # Compare validation velocities to predicted velocities using R^2 score\n",
    "            r2 = r2_score(V_val.flatten(), V_pred.flatten())\n",
    "            fold_r2s.append(r2)\n",
    "        \n",
    "        avg_r2 = np.average(np.array(fold_r2s))\n",
    "        df = pd.concat([df, pd.DataFrame([{\"sigma\": sigma, \"lambda\": l, \"value\": round(avg_r2, 3)}])], ignore_index=True)\n",
    "\n",
    "print(np.max(np.array(df['value'])))\n",
    "\n",
    "pivot_df = df.pivot(index=\"sigma\", columns=\"lambda\", values=\"value\")\n",
    "print(pivot_df)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b9/z73nffbd0jj6kn3qz4t9mgj00000gn/T/ipykernel_61928/3318704544.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\"sigma\": sigma, \"lambda\": l, \"value\": round(avg_r2, 3)}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.468\n",
      "lambda  0.1     1.0     10.0    100.0   1000.0\n",
      "sigma                                         \n",
      "0.4      0.343   0.343   0.344   0.346   0.326\n",
      "1.0      0.436   0.437   0.439   0.444   0.398\n",
      "1.6      0.456   0.457   0.461   0.468   0.404\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- <u>Implement Gaussian temporal smoothing + ridge regression as outlined above</u>.\n",
    "- **How does the quality of hand velocity predictions vary with the smoothing window length $\\sigma$? How do you interpret that?** You might want to experiment with values between 20 and 80 ms.\n",
    "- **Comment on the suitability of this simple decoding strategy for online (“on the fly”) decoding of movement in a BMI context (consider e.g. feasability, computational tractability, and accuracy). Can you think of a small modification to the above approach that would improve applicability to online decoding?** (bonus points for  implementing it!)\n",
    "- The hand velocity data provided in `data[\"hand_train\"]` had actually been shifted backward by 120ms relative to the neural data (and similarly for the test set, which was not given to you). **Can you speculate about why we did that**?"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:45.207906Z",
     "start_time": "2024-12-18T15:00:45.017212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# On-the-fly decoding\n",
    "def online_W_star(V_X_T, X_X_T, x, v, K, l):\n",
    "    v_x_T = np.tensordot(v, x.T, axes=([2, 1], [0, 1]))\n",
    "    x_x_T = np.tensordot(x, x.T, axes=([2, 1], [0, 1]))\n",
    "    \n",
    "    V_X_T_prime = V_X_T*(K/(K+1)) + v_x_T*(1/(K+1))\n",
    "    X_X_T_prime = X_X_T*(K/(K+1)) + x_x_T*(1/(K+1))\n",
    "    \n",
    "    # Same as before\n",
    "    I_N = np.eye(X.shape[0])\n",
    "    inv_mat = np.linalg.inv(X_X_T_prime + l * I_N)\n",
    "    \n",
    "    W_star = np.tensordot(V_X_T_prime, inv_mat, axes=([1], [0]))\n",
    "    \n",
    "    return W_star, V_X_T_prime, X_X_T_prime, K+1\n",
    "\n",
    "K = 380\n",
    "l = 100\n",
    "sigma = 1.6\n",
    "neural_train = data[\"neural_train\"][:, :K, :]\n",
    "hand_train = data[\"hand_train\"][:, :K, :]\n",
    "\n",
    "X = gaussian_smooth(sigma, neural_train)\n",
    "V = hand_train\n",
    "\n",
    "V_X_T = np.tensordot(V, X.T, axes=([2, 1], [0, 1]))\n",
    "X_X_T = np.tensordot(X, X.T, axes=([2, 1], [0, 1]))\n",
    "\n",
    "W_star = compute_W_star(X, V, l)\n",
    "\n",
    "# Comment out to remove online decoding\n",
    "while K < 400:\n",
    "    online_neural_train = data[\"neural_train\"][:, K:K+1, :]\n",
    "    online_hand_train = data[\"hand_train\"][:, K:K+1, :]\n",
    "\n",
    "    W_star, V_X_T, X_X_T, K = online_W_star(V_X_T, X_X_T, online_neural_train, online_hand_train, K, l)\n",
    "\n",
    "neural_test = data[\"neural_test\"]\n",
    "neural_test_smooth = gaussian_smooth(sigma, neural_test)\n",
    "\n",
    "V_test = np.tensordot(W_star, neural_test_smooth, axes=([1],[0]))\n",
    "np.save(\"outputs/V_test_online.npy\", V_test)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Kalman filter-based decoding\n",
    "\n",
    "We now turn to a more sophisticated decoder based on a Kalman filter/smoother.\n",
    "\n",
    "### 3.1 An autoregressive prior for hand kinematics\n",
    "\n",
    "A 10-dimensional linear latent dynamical system (“LDS”; cf lecture notes) was pre-trained for you on the hand velocity data in the training set; specifically, we consider the following generative model:\n",
    "\n",
    "$$\n",
    "(1) \\qquad z_{k, 0} \\sim \\mathcal{N}(\\mu_0, \\Sigma_0) \\\\ \n",
    "(2) \\qquad z_{k, t+1} = A z_{k, t} + \\epsilon_{k, t+1} \\quad \\text{with } \\epsilon_{k, t+1} \\sim \\mathcal{N}(0, Q) \\\\\n",
    "(3) \\qquad v_{k, t} = C z_{k, t} + \\eta_{k, t} \\quad \\text{with } \\eta_{k, t} \\sim \\mathcal{N}(0, R)\n",
    "$$\n",
    "\n",
    "where $z_{k, t} \\in \\mathbb{R}^{10}$ is the latent state in time bin $t$ of trial $k$, and $v_{k, t} \\in \\mathbb{R}^2$ is the corresponding hand velocity. \n",
    "\n",
    "The parameters of this LDS can be found in the same `data` dictionary as above, with the following keys:\n",
    "- \"hand_KF_A\" (`10 × 10`): state matrix $A$\n",
    "- \"hand_KF_C\" (`2 × 10`): output matrix $C$\n",
    "- \"hand_KF_mu0\" (`10 × 1`): initial prior mean $\\mu_0$\n",
    "- \"hand_KF_Sigma0\" (`10 × 10`): initial prior covariance $\\Sigma_0$\n",
    "- \"hand_KF_Q\" (`10 × 10`): process noise covariance matrix $Q$\n",
    "- \"hand_KF_R\" (`2 × 2`): observation noise covariance matrix $R$\n",
    "\n",
    "<u>Write your own Kalman smoother implementation and use it to compute the mean $\\hat{z}_{k, 1:T}$ of the smoothing distribution $p(z_{k, t} | v_{k, 1:T})$, for each trial $k$ in the training set.</u>\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:45.222431Z",
     "start_time": "2024-12-18T15:00:45.220389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pull in the data \n",
    "A = data[\"hand_KF_A\"]\n",
    "C = data[\"hand_KF_C\"]\n",
    "mu0 = data[\"hand_KF_mu0\"]\n",
    "Sigma0 = data[\"hand_KF_Sigma0\"]\n",
    "Q = data[\"hand_KF_Q\"]\n",
    "R = data[\"hand_KF_R\"]"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:45.240225Z",
     "start_time": "2024-12-18T15:00:45.234800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Smooth the data with a Kalman smoother\n",
    "neural_train = data[\"neural_train\"] # Fresh copy of data\n",
    "hand_train = data[\"hand_train\"] \n",
    "neural_test = data[\"neural_test\"] \n",
    "N, K, T = neural_train.shape # Shape is neurons (n) x trials (k) x times (t)\n",
    "LDS_dim = 10"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:45.256938Z",
     "start_time": "2024-12-18T15:00:45.253110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First, perform Kalman filtering\n",
    "\n",
    "# Create arrays to hold intermediate values for both mu and Sigma\n",
    "mu_array = np.zeros(shape=(K, T, LDS_dim))\n",
    "mu0_repeat = np.repeat(mu0, K, axis=1).T\n",
    "mu_array[:, 0, :] = mu0_repeat\n",
    "\n",
    "Sigma_array = np.zeros(shape=(T, LDS_dim, LDS_dim)) # Condition independent\n",
    "Sigma_array[0] = Sigma0[np.newaxis, :, :]\n",
    "\n",
    "for t in range(1, T):\n",
    "    # First, find Sigma t using Sigma t-1    \n",
    "    C_T_R_1_C = np.matmul(np.matmul(C.T, np.linalg.inv(R)), C)\n",
    "    A_Sigma_A_T = np.matmul(np.matmul(A, Sigma_array[(t-1)]), A.T)\n",
    "    Q_Q_T = np.matmul(Q, Q.T)\n",
    "    Sigma_inv = C_T_R_1_C + np.linalg.inv(A_Sigma_A_T + Q_Q_T)\n",
    "    \n",
    "    # Update the next Sigma at time t\n",
    "    Sigma_array[t] = np.linalg.inv(Sigma_inv)\n",
    "    \n",
    "    # Now, use Sigma t to find mu t\n",
    "    v_t = hand_train[:, :, t] # Use the current velocity at time t to update the hidden state at time t\n",
    "    C_A = np.matmul(C, A)\n",
    "    C_A_mu = np.matmul(C_A, mu_array[:, (t-1), :].T)    \n",
    "    pred_error = v_t - C_A_mu\n",
    "    assert pred_error.shape == (2,400), 'Shape of prediction error array should be 2 (x & y velocities) by K.'\n",
    "    \n",
    "    kalman_gain = np.matmul(np.matmul(Sigma_array[t], C.T), np.linalg.inv(R))\n",
    "    correction = np.matmul(kalman_gain, pred_error).T # Just because we want conditions by 10\n",
    "    assert correction.shape == (400, 10), 'Shape of correction should be K by 10 (model trained with 10 params for mu)'\n",
    "    \n",
    "    # Update the next mu at time t\n",
    "    A_mu_t = np.matmul(A, mu_array[:, (t-1), :].T).T # Shape is conditions (K) by time (T)\n",
    "    assert A_mu_t.shape == (400, 10), 'Shape of A x mu_t should be K by 10 (model trained with 10 params for mu)'\n",
    "\n",
    "    mu_array[:, t] = A_mu_t + correction\n",
    "\n",
    "print(f'mu array shape: {mu_array.shape}, Sigma array shape: {Sigma_array.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu array shape: (400, 16, 10), Sigma array shape: (16, 10, 10)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:45.326034Z",
     "start_time": "2024-12-18T15:00:45.319495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Second, do a backward pass to perform Kalman smoothing \n",
    "\n",
    "# Create arrays to hold intermediate values again\n",
    "mu_array_tilde = np.zeros(shape = mu_array.shape)\n",
    "Sigma_array_tilde = np.zeros(shape = Sigma_array.shape)\n",
    "\n",
    "# Populate the last element in both arrays with the last element in mu array and Sigma array\n",
    "mu_array_tilde[:, T-1] = mu_array[:, T-1]\n",
    "Sigma_array_tilde[T-1] = Sigma_array[T-1]\n",
    "print(Sigma_array_tilde)\n",
    "\n",
    "for t in range(T-2, -1, -1): # \n",
    "    A_Sigma_A_T = np.matmul(np.matmul(A, Sigma_array[t]), A.T)\n",
    "    Q_Q_T = np.matmul(Q, Q.T)\n",
    "    P_t = A_Sigma_A_T + Q_Q_T\n",
    "    P_t_inv = np.linalg.inv(P_t)\n",
    "    G_t = np.matmul(np.matmul(Sigma_array[t], A.T), P_t_inv)\n",
    "    \n",
    "    A_mu_t = np.matmul(A, mu_array[:, t].T).T # Use current time\n",
    "    # print(f'A x mu t shape: {A_mu_t.shape}')\n",
    "    # print(f'mu tilde t+1 shape: {mu_array_tilde[:, t+1].shape}')\n",
    "    mu_array_tilde[:, t] = mu_array[:, t] + np.matmul(G_t, (mu_array_tilde[:, t+1] - A_mu_t).T).T\n",
    "    \n",
    "    diff = Sigma_array_tilde[t+1] - P_t\n",
    "    G_t_diff_G_t_T = np.matmul(G_t, np.matmul(diff, G_t.T))\n",
    "    Sigma_array_tilde[t] = Sigma_array[t] + G_t_diff_G_t_T\n",
    "\n",
    "print(Sigma_array_tilde)\n",
    "\n",
    "# Second, do a backward pass to perform Kalman smoothing \n",
    "\n",
    "# Create arrays to hold intermediate values again\n",
    "mu_array_tilde = np.zeros(shape=mu_array.shape)\n",
    "Sigma_array_tilde = np.zeros(shape=Sigma_array.shape)\n",
    "\n",
    "# Populate the last element in both arrays with the last element in mu array and Sigma array\n",
    "mu_array_tilde[:, T - 1] = mu_array[:, T - 1]\n",
    "Sigma_array_tilde[T - 1] = Sigma_array[T - 1]\n",
    "print(Sigma_array_tilde)\n",
    "\n",
    "for t in range(T - 2, -1, -1):  # \n",
    "    A_Sigma_A_T = np.matmul(np.matmul(A, Sigma_array[t]), A.T)\n",
    "    Q_Q_T = np.matmul(Q, Q.T)\n",
    "    P_t = A_Sigma_A_T + Q_Q_T\n",
    "    P_t_inv = np.linalg.inv(P_t)\n",
    "    G_t = np.matmul(np.matmul(Sigma_array[t], A.T), P_t_inv)\n",
    "\n",
    "    A_mu_t = np.matmul(A, mu_array[:, t].T).T  # Use current time\n",
    "    # print(f'A x mu t shape: {A_mu_t.shape}')\n",
    "    # print(f'mu tilde t+1 shape: {mu_array_tilde[:, t+1].shape}')\n",
    "    mu_array_tilde[:, t] = mu_array[:, t] + np.matmul(G_t, (mu_array_tilde[:, t + 1] - A_mu_t).T).T\n",
    "\n",
    "    diff = Sigma_array_tilde[t + 1] - P_t\n",
    "    G_t_diff_G_t_T = np.matmul(G_t, np.matmul(diff, G_t.T))\n",
    "    Sigma_array_tilde[t] = Sigma_array[t] + G_t_diff_G_t_T"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 2.5206984  -1.79341835 -0.40980985 ... -1.01215356 -1.65302506\n",
      "    0.30451372]\n",
      "  [-1.79341835  4.4222816  -0.77600581 ...  1.61527241  0.27339822\n",
      "   -1.13598427]\n",
      "  [-0.40980985 -0.77600581  0.97365533 ...  0.80015531  0.38267228\n",
      "    0.61159174]\n",
      "  ...\n",
      "  [-1.01215356  1.61527241  0.80015531 ...  4.27184294  0.46690649\n",
      "   -0.1476497 ]\n",
      "  [-1.65302506  0.27339822  0.38267228 ...  0.46690649  1.82390682\n",
      "    0.33731559]\n",
      "  [ 0.30451372 -1.13598427  0.61159174 ... -0.1476497   0.33731559\n",
      "    1.82213213]]]\n",
      "[[[ 3.51785205e-02 -1.91963718e-02  8.77882488e-03 ...  1.49324286e-03\n",
      "   -4.54198434e-03 -3.91441696e-02]\n",
      "  [-1.91963718e-02  1.64889315e-02  1.58026257e-02 ... -2.14788620e-03\n",
      "    7.24811736e-03  2.07365730e-02]\n",
      "  [ 8.77882488e-03  1.58026257e-02  1.60841531e-01 ... -2.18761722e-02\n",
      "    2.73832506e-02  1.09992830e-02]\n",
      "  ...\n",
      "  [ 1.49324286e-03 -2.14788620e-03 -2.18761722e-02 ...  5.67053959e-03\n",
      "   -2.70523924e-03 -7.42192750e-03]\n",
      "  [-4.54198434e-03  7.24811736e-03  2.73832506e-02 ... -2.70523924e-03\n",
      "    8.67548012e-03  1.56120903e-03]\n",
      "  [-3.91441696e-02  2.07365730e-02  1.09992830e-02 ... -7.42192750e-03\n",
      "    1.56120903e-03  7.25029582e-02]]\n",
      "\n",
      " [[ 8.03294906e-03 -8.34644739e-03 -6.34698778e-03 ... -1.66039571e-03\n",
      "   -3.41449954e-03 -2.03754962e-02]\n",
      "  [-8.34644739e-03  2.16525211e-02  1.94501051e-02 ...  9.55732690e-03\n",
      "   -1.92843723e-03  2.50763298e-02]\n",
      "  [-6.34698778e-03  1.94501051e-02  5.37302386e-02 ...  1.10354278e-02\n",
      "   -1.04397769e-04  1.13889593e-02]\n",
      "  ...\n",
      "  [-1.66039571e-03  9.55732690e-03  1.10354278e-02 ...  1.07966145e-02\n",
      "   -7.79621801e-03 -3.24980326e-03]\n",
      "  [-3.41449954e-03 -1.92843723e-03 -1.04397769e-04 ... -7.79621801e-03\n",
      "    1.24812682e-02  1.50264955e-02]\n",
      "  [-2.03754962e-02  2.50763298e-02  1.13889593e-02 ... -3.24980326e-03\n",
      "    1.50264955e-02  1.28287079e-01]]\n",
      "\n",
      " [[ 1.89414564e-02 -1.55624306e-02 -4.17754821e-03 ... -2.16326078e-02\n",
      "    2.32169276e-03 -6.17253051e-03]\n",
      "  [-1.55624306e-02  5.84011384e-02  1.12784844e-02 ...  2.98557616e-02\n",
      "   -2.06917805e-02  2.67058875e-03]\n",
      "  [-4.17754821e-03  1.12784844e-02  3.19469937e-02 ...  1.41415013e-02\n",
      "   -5.82844778e-03  6.30102915e-03]\n",
      "  ...\n",
      "  [-2.16326078e-02  2.98557616e-02  1.41415013e-02 ...  4.58561842e-02\n",
      "   -1.70047505e-02 -2.65286419e-02]\n",
      "  [ 2.32169276e-03 -2.06917805e-02 -5.82844778e-03 ... -1.70047505e-02\n",
      "    1.64340033e-02  1.81688542e-02]\n",
      "  [-6.17253051e-03  2.67058875e-03  6.30102915e-03 ... -2.65286419e-02\n",
      "    1.81688542e-02  1.33662467e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.84850527e+00 -9.46316859e-01 -5.15581956e-01 ... -6.66772883e-01\n",
      "   -1.29123208e+00 -1.80138226e-02]\n",
      "  [-9.46316859e-01  2.09372396e+00 -9.79175785e-02 ...  3.88974749e-01\n",
      "   -1.19970243e-01 -3.22375746e-01]\n",
      "  [-5.15581956e-01 -9.79175785e-02  6.38083284e-01 ...  1.03801130e+00\n",
      "    3.88325949e-01  2.49236341e-01]\n",
      "  ...\n",
      "  [-6.66772883e-01  3.88974749e-01  1.03801130e+00 ...  3.14046801e+00\n",
      "    1.39066543e-01 -5.98133668e-02]\n",
      "  [-1.29123208e+00 -1.19970243e-01  3.88325949e-01 ...  1.39066543e-01\n",
      "    1.48696165e+00  3.75244961e-01]\n",
      "  [-1.80138226e-02 -3.22375746e-01  2.49236341e-01 ... -5.98133668e-02\n",
      "    3.75244961e-01  1.27100453e+00]]\n",
      "\n",
      " [[ 2.38575402e+00 -1.77478160e+00 -4.26673492e-01 ... -1.14180377e+00\n",
      "   -1.60135042e+00  1.73349991e-01]\n",
      "  [-1.77478160e+00  3.44335219e+00 -2.05528881e-01 ...  1.28317829e+00\n",
      "    3.46331188e-01 -5.74688679e-01]\n",
      "  [-4.26673492e-01 -2.05528881e-01  6.57567212e-01 ...  1.00524973e+00\n",
      "    3.28521520e-01  2.94645905e-01]\n",
      "  ...\n",
      "  [-1.14180377e+00  1.28317829e+00  1.00524973e+00 ...  3.92124986e+00\n",
      "    4.11029324e-01 -1.30929266e-01]\n",
      "  [-1.60135042e+00  3.46331188e-01  3.28521520e-01 ...  4.11029324e-01\n",
      "    1.68848327e+00  2.61869567e-01]\n",
      "  [ 1.73349991e-01 -5.74688679e-01  2.94645905e-01 ... -1.30929266e-01\n",
      "    2.61869567e-01  1.36815212e+00]]\n",
      "\n",
      " [[ 2.52069840e+00 -1.79341835e+00 -4.09809845e-01 ... -1.01215356e+00\n",
      "   -1.65302506e+00  3.04513721e-01]\n",
      "  [-1.79341835e+00  4.42228160e+00 -7.76005810e-01 ...  1.61527241e+00\n",
      "    2.73398217e-01 -1.13598427e+00]\n",
      "  [-4.09809845e-01 -7.76005810e-01  9.73655329e-01 ...  8.00155307e-01\n",
      "    3.82672280e-01  6.11591743e-01]\n",
      "  ...\n",
      "  [-1.01215356e+00  1.61527241e+00  8.00155307e-01 ...  4.27184294e+00\n",
      "    4.66906488e-01 -1.47649699e-01]\n",
      "  [-1.65302506e+00  2.73398217e-01  3.82672280e-01 ...  4.66906488e-01\n",
      "    1.82390682e+00  3.37315589e-01]\n",
      "  [ 3.04513721e-01 -1.13598427e+00  6.11591743e-01 ... -1.47649699e-01\n",
      "    3.37315589e-01  1.82213213e+00]]]\n",
      "[[[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 2.5206984  -1.79341835 -0.40980985 ... -1.01215356 -1.65302506\n",
      "    0.30451372]\n",
      "  [-1.79341835  4.4222816  -0.77600581 ...  1.61527241  0.27339822\n",
      "   -1.13598427]\n",
      "  [-0.40980985 -0.77600581  0.97365533 ...  0.80015531  0.38267228\n",
      "    0.61159174]\n",
      "  ...\n",
      "  [-1.01215356  1.61527241  0.80015531 ...  4.27184294  0.46690649\n",
      "   -0.1476497 ]\n",
      "  [-1.65302506  0.27339822  0.38267228 ...  0.46690649  1.82390682\n",
      "    0.33731559]\n",
      "  [ 0.30451372 -1.13598427  0.61159174 ... -0.1476497   0.33731559\n",
      "    1.82213213]]]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Building an LDS model of neural data using supervised learning\n",
    "\n",
    "Conceptually, the latents $z_{k, 1:T}$ introduced above contain signals related to the velocity of the hand, its acceleration, and potentially higher-order derivatives too — all signals which we have good reasons to suspect that neural activity in M1 is strongly related to. Eqs (1) and (2) above provide a good autoregressive prior model for the temporal dynamics of these signals, and you are now going to use this prior in a generative LDS model of _neural data_, substituting the hand-related likelihood (Eq 3) with a neural likelihood:\n",
    "\n",
    "$$\n",
    "(4) \\qquad x_{k, t} = D z_{k, t} + \\xi_{k, t} \\quad \\text{with } \\xi_{k, t} \\sim \\mathcal{N}(0, S)\n",
    "$$\n",
    "\n",
    "where $x_{k, t}$ denotes neural spike counts in the $t^\\text{th}$ time bin of trial $k$.\n",
    "\n",
    "The combination of Eqs (1), (2) and (4) forms an LDS model which you will be able to invert using Kalman filtering to obtain a filtered posterior $p(z_{k', t} | x_{k', 0:t})$ for any test trial $k'$. From there, you will use Eq. (3) to obtain a filtered predictive distribution for the hand velocity in each test trial, $p(v_{k', t} | x_{k', 0:t})$.\n",
    "\n",
    "- <u>Begin by centering the neural data (both training and testing sets) by removing, for each neuron, its mean activity across both trials and time in the training set.</u>\n",
    "- <u>Fit the likelihood parameters $D$ and $S$ through supervised learning, by maximizing the joint log-likelihood $\\log p(\\hat{z}_{k, 1:T}, x_{k, 1:T})$ averaged over all trials in the training set, where $\\hat{z}_{k,1:T}$ is the posterior mean you obtained in Section 3.1.</u>\n",
    "To do this, write down the average joint log likelihood and **show that it is maximized by the following parameter settings**:\n",
    "    - $ \\displaystyle D^\\star = \\left(\\sum_{k, t} x_{k, t} \\hat{z}_{k, t}^\\top \\right) \\left( \\sum_{k, t} \\hat{z}_{k, t} \\hat{z}_{k, t}^\\top \\right)^{-1} $\n",
    "    - $ \\displaystyle S^\\star = \\frac{1}{KT} \\left( \\sum_{k, t} x_{k, t} x_{k, t}^\\top - D^\\star \\sum_{k, t} \\hat{z}_{k, t} x_{k, t}^\\top \\right) $ where $K$ is the number of trials in the training set. **Include your derivations in your report.**"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:45.354414Z",
     "start_time": "2024-12-18T15:00:45.348551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First, center the data by subtracted out the mean wrt condition and time\n",
    "X_uncentered = data['neural_train'] \n",
    "X_avg_cond_time = np.average(X_uncentered, axis = [1, 2])\n",
    "X_avg_cond_time = X_avg_cond_time[:, np.newaxis, np.newaxis]\n",
    "X = X_uncentered - X_avg_cond_time\n",
    "\n",
    "Z_post = mu_array_tilde # Posterior of the values\n",
    "print(X.shape, Z_post.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 400, 16) (400, 16, 10)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:45.603526Z",
     "start_time": "2024-12-18T15:00:45.377284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now, find D* and S* using the parameter settings defined above\n",
    "sum_1 = np.zeros(shape = (N, LDS_dim))\n",
    "sum_2 = np.zeros(shape = (LDS_dim, LDS_dim))\n",
    "sum_3 = np.zeros(shape = (N, N))\n",
    "sum_4 = np.zeros(shape = (LDS_dim, N))\n",
    "\n",
    "for k in range(K):\n",
    "    for t in range(T):\n",
    "        x_k_t = (X[:, k, t])[:, np.newaxis] # Dimension should be N x 1\n",
    "        z_k_t = (Z_post[k, t])[:, np.newaxis] # Dimension should be 10 x 1\n",
    "        \n",
    "        sum_1 += np.matmul(x_k_t, z_k_t.T)\n",
    "        sum_2 += np.matmul(z_k_t, z_k_t.T)\n",
    "        sum_3 += np.matmul(x_k_t, x_k_t.T)\n",
    "        sum_4 += np.matmul(z_k_t, x_k_t.T)\n",
    "        \n",
    "D_star = np.matmul(sum_1, np.linalg.inv(sum_2))\n",
    "S_star = (1/(K*T)) * (sum_3 - np.matmul(D_star, sum_4))\n",
    "print(D_star.shape, S_star.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 10) (162, 162)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Using Kalman filtering to predict the hand velocity\n",
    "\n",
    "- Based on the model obtained in Section 3.2, <u>write your own Kalman filter implementation and compute the filtered posterior $p(z_{k', t} | x_{k', 0:t}) $ for each trial $k'$ in the test set.</u> What we are really interested in is the mean $\\bar{z}_{k', t}$ of this filtered posterior, as our best prediction of the momentary hand velocity $v_{k', t}$ is then given by $\\hat{v}_{k', t} = C \\bar{z}_{k', t}$.\n",
    "- <u>Submit your predictions to http://4G10.cbl-cambridge.org (note: http, not https) in the same format as described in Section 2. Please select \"Kalman filtering\" in the dropdown list. Once again, you will receive immediate feedback in the form of an $R^2$ coefficient.</u> **Include this result in your report, and discuss; in particular, why do you think these predictions are much better than those of Section 2?**\n",
    "- As in Section 2, **comment on the suitability of this more sophisticated decoding strategy for online decoding of movement in a BCI context**.\n",
    "- Finally, **what approach(es) would you suggest to improve decoding performance even further? Include a discussion of the tradeoffs that would arise with these alternative approaches.** (max 1 page in your report)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:45.630031Z",
     "start_time": "2024-12-18T15:00:45.627626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "neural_test = data[\"neural_test\"] # Fresh copy of data\n",
    "N, K, T = neural_test.shape # Shape is neurons (n) x trials (k) x times (t)\n",
    "LDS_dim = 10"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:45.663622Z",
     "start_time": "2024-12-18T15:00:45.653178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Kalman filtering for the new model\n",
    "\n",
    "# Create arrays to hold intermediate values for both mu and Sigma\n",
    "mu_array = np.zeros(shape=(K, T, LDS_dim))\n",
    "mu0_repeat = np.repeat(mu0, K, axis=1).T\n",
    "mu_array[:, 0, :] = mu0_repeat\n",
    "\n",
    "Sigma_array = np.zeros(shape=(T, LDS_dim, LDS_dim)) # Condition independent\n",
    "Sigma_array[0] = Sigma0[np.newaxis, :, :]\n",
    "\n",
    "for t in range(1, T):\n",
    "    # First, find Sigma t using Sigma t-1    \n",
    "    D_T_R_1_D = np.matmul(np.matmul(D_star.T, np.linalg.inv(S_star)), D_star)\n",
    "    A_Sigma_A_T = np.matmul(np.matmul(A, Sigma_array[(t-1)]), A.T)\n",
    "    Q_Q_T = np.matmul(Q, Q.T)\n",
    "    Sigma_inv = D_T_R_1_D + np.linalg.inv(A_Sigma_A_T + Q_Q_T)\n",
    "\n",
    "    # Update the next Sigma at time t\n",
    "    Sigma_array[t] = np.linalg.inv(Sigma_inv)\n",
    "\n",
    "    # Now, use Sigma t to find mu t\n",
    "    x_t = neural_test[:, :, t] # Use the firing rate at time t to update the hidden state at time t\n",
    "    D_A = np.matmul(D_star, A)\n",
    "    D_A_mu = np.matmul(D_A, mu_array[:, (t-1), :].T)    \n",
    "    pred_error = x_t - D_A_mu\n",
    "    assert pred_error.shape == (N, K), f'Shape of prediction error array should be {N} by {K} (N x K) but was {pred_error.shape}.'\n",
    "\n",
    "    kalman_gain = np.matmul(np.matmul(Sigma_array[t], D_star.T), np.linalg.inv(S_star))\n",
    "    correction = np.matmul(kalman_gain, pred_error).T # Just because we want conditions by 10\n",
    "    assert correction.shape == (K, LDS_dim), f'Shape of correction should be {K} by {LDS_dim} (model trained with {LDS_dim} params for mu) but was {correction.shape}.'\n",
    "\n",
    "    # # Update the next mu at time t\n",
    "    A_mu_t = np.matmul(A, mu_array[:, (t-1), :].T).T # Shape is conditions (K) by time (T)\n",
    "    assert A_mu_t.shape == (K, LDS_dim), f'Shape of A*mu_t should be {K} by {LDS_dim} but was {A_mu_t.shape}.'\n",
    "\n",
    "    mu_array[:, t] = A_mu_t + correction\n",
    "\n",
    "print(f'mu array shape: {mu_array.shape}, Sigma array shape: {Sigma_array.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu array shape: (100, 16, 10), Sigma array shape: (16, 10, 10)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:45.693118Z",
     "start_time": "2024-12-18T15:00:45.690765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# mu_array holds the Kalman filtered means of the posterior distribution\n",
    "# Use Equation 3 (from modeling, now for application so no noise) to predict test velocities\n",
    "V_test = np.tensordot(C, mu_array, axes=(1, 2))\n",
    "\n",
    "assert V_test.shape == (2, K, T), f'V test shape should be (2, {K}, {T} but was {V_test.shape}'\n",
    "np.save(\"outputs/V_test_kalman.npy\", V_test)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:45.720785Z",
     "start_time": "2024-12-18T15:00:45.719492Z"
    }
   },
   "cell_type": "code",
   "source": "# Your test R2 is: 0.735",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing up\n",
    "\n",
    "\n",
    "Please write up your findings in a report to be submitted on Moodle in PDF format, and **include all your code in the Appendix**. Please clearly include your candidate number, NOT your name, on the front page. Your report should address all the questions raised in this notebook, be structured around the Sections of this notebook, and **be a maximum of five A4 pages** excluding any Appendix (minimum font size 11pt, minimum margins 1.5cm on each side).\n",
    "\n",
    "You are very much encouraged to think of data/results visualisations to best support the exposition of your results. You are also encouraged to report on any specific problems/difficulties that arose in your implementation of the various algorithms, and how you addressed those."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:45.748498Z",
     "start_time": "2024-12-18T15:00:45.747355Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:45.777808Z",
     "start_time": "2024-12-18T15:00:45.776605Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
